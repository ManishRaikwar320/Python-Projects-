"""
Web Scraper for Real-time Data (Python + Scrapy + BeautifulSoup)
üëâ ‡§Ø‡§π Python Web Scraper ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§∏‡•á ‡§°‡•á‡§ü‡§æ ‡§∏‡•ç‡§ï‡•ç‡§∞‡•à‡§™ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§á‡§∏ ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§π‡§Æ Amazon/Flipkart ‡§™‡§∞ Product Prices ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á ‡§î‡§∞ Email/Telegram ‡§ï‡•á ‡§ú‡§∞‡§ø‡§è Notification ‡§≠‡•á‡§ú ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§

üîπ Step-by-Step Implementation
‚úÖ Step 1: Install Dependencies
‚úÖ Step 2: Website ‡§∏‡•á Data Extract ‡§ï‡§∞‡•á‡§Ç
‚úÖ Step 3: CSV ‡§Æ‡•á‡§Ç Save ‡§ï‡§∞‡•á‡§Ç
‚úÖ Step 4: Automate ‡§ï‡§∞‡§ï‡•á Price Drop Alert ‡§≠‡•á‡§ú‡•á‡§Ç

""" 


import requests
from bs4 import BeautifulSoup
import pandas as pd
import smtplib
import schedule
import time
from datetime import datetime

# Amazon Product URL (‡§Ö‡§™‡§®‡§æ Product URL ‡§°‡§æ‡§≤‡•á‡§Ç)
URL = "https://www.amazon.in/dp/B0BSF4KY4Z"  # Example Product URL

# Headers (Amazon Bot Detection ‡§∏‡•á ‡§¨‡§ö‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è)
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept-Language": "en-US, en;q=0.5"
}

# Price Scraping Function
def get_price():
    response = requests.get(URL, headers=HEADERS)
    soup = BeautifulSoup(response.content, "html.parser")

    # Product Title Scraping
    title = soup.find("span", id="productTitle").get_text(strip=True)

    # Price Scraping
    price = soup.find("span", class_="a-price-whole").get_text(strip=True)

    print(f"Product: {title}")
    print(f"Current Price: ‚Çπ{price}")

    return title, price

# Save Data to CSV
def save_to_csv(title, price):
    filename = "price_tracker.csv"
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    with open(filename, "a", newline="") as file:
        writer = pd.DataFrame([[now, title, price]])
        writer.to_csv(filename, mode="a", header=False, index=False)
        print("‚úÖ Data saved to CSV")

# Send Email Alert
def send_email(title, price):
    sender_email = "your_email@gmail.com"  # ‡§Ö‡§™‡§®‡§æ Email ‡§°‡§æ‡§≤‡•á‡§Ç
    receiver_email = "receiver_email@gmail.com"  # ‡§ú‡§ø‡§∏‡§ï‡•ã Notification ‡§≠‡•á‡§ú‡§®‡§æ ‡§π‡•à
    password = "your_email_password"  # App Password (2-Step Authentication On ‡§ï‡§∞‡•á‡§Ç)

    subject = f"Price Drop Alert: {title}"
    body = f"The price of {title} has dropped to ‚Çπ{price}!\nCheck here: {URL}"

    message = f"Subject: {subject}\n\n{body}"

    # Gmail SMTP Server
    with smtplib.SMTP("smtp.gmail.com", 587) as server:
        server.starttls()
        server.login(sender_email, password)
        server.sendmail(sender_email, receiver_email, message)

    print("üìß Email Sent!")

# Automate Scraper
def job():
    title, price = get_price()
    save_to_csv(title, price)
    if int(price.replace(",", "")) < 70000:
        send_email(title, price)

# Run Every 6 Hours
schedule.every(6).hours.do(job)

while True:
    schedule.run_pending()
    time.sleep(1)
